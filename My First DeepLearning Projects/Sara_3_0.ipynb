{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit909-creator/Rohit909-creator/blob/main/Sara_3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LzHboeGRdvh"
      },
      "source": [
        "# SARA for IEEE SCT SB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-CKL6LFRo1N"
      },
      "source": [
        "As if now this 3rd version of Sara knows to chat,I got to train her with the action_pred_data for action prediction and also a task classification layer for both conversation and app action performance\n",
        "\n",
        "Note: Action prediction has been done by SARA 2.0 but since a transformer decoder layer is better than LSTM's SARA 3.0 is being made"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crfy-UQXqY92",
        "outputId": "2add0b36-8fc5-4fc3-e634-737ebb2b1160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 249 kB 24.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 47.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 41.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 365 kB 25.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 9.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 24.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 46.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 66.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 56.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 69.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 72.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 66.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 71.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 41.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.1 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install simpletransformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH8BjVK5LaSD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from simpletransformers.language_representation import RepresentationModel\n",
        "import numpy as np\n",
        "import pandas as ps\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnZLOiYJNSE1"
      },
      "outputs": [],
      "source": [
        "intents = {'intents':[{'tag':'greetings','patterns':['hello','hi','hola','namaskar'],'responses':['hello','hi','how can i help']},\n",
        "                      {'tag':'actions','patterns':['get me to pdf','take me to pdf','open pdf',\n",
        "                      'go to assignments','take me to assignments','open assignments','take me to voice notes'\n",
        "                      ,'open voice notes','take me to voice notes','open voice notes','go back','open recent','i would like to view my assignments','i want to access the assignments page',\n",
        "                      'i want to get to the assignments page','Take me to chapter 1 of assignments','Take me to chapter 1 in my voice notes','Open my voice notes and lead me to chapter 1',\n",
        "                      'Take me to chapter 1 of the pdf','I would like to open the pdf and go to chapter 1','Let me see chapter 1 of the PDF'],'responses':['ok','here you go','how can i help']},\n",
        "\n",
        "                                                                                \n",
        "                      {'tag':'thanks','patterns':['thank you','thanks'],'responses':['you are welcome','happy to help']},\n",
        "                      {'tag':'read','patterns':['how many left to complete in pdf','how many left New in pdf','how many have I completed in pdf','how many assignments remain to be completed','what are the remaining assignments','the number of assignments left to complete','is there any work left to do'],'responses':['read']},\n",
        "                      {'tag':'bye','patterns':['bye bye','ta ta','see ya','shutdown'],'responses':['bye bye']},\n",
        "                      {'tag':'wishing','patterns':['how are you','you good','how are you feeling','do you feel well','good to hear from you','what is going on with you',\"what's up with you\",'you seem to be having a hard time'],'responses':['I am good',\"I am fine\",'Yeah I am good']},\n",
        "                      {'tag':'sort','patterns':['arange this in datewise order','sort these in datewise order','arrange these pending wise order'],'responses':['sorting,,,']},\n",
        "                      {'tag':'bookmark','patterns':['bookmark this page','save this page','note this page for later','keep this page handy'],'responses':['bookmarking']},\n",
        "                      {'tag':'maker','patterns':['who created you','who is your maker','the name of your father',''],'responses':['I am SARA I originless']},\n",
        "                      {'tag':'age','patterns':['how old are you','what is your age'],'responses':['I dont have an age as of now',\"is it nwccessary to have that one\"]},\n",
        "                      {'tag':'place','patterns':['where do you live','where is your place'],'responses':['Look behind you',\"I am watching you\",\"Look around you\"]},\n",
        "                      {'tag':'locate','patterns':['find me','locate me'],'responses':['I found you',\"gotcha\"]},\n",
        "                      {'tag':'user identity','patterns':['who am i','do you know me','say my name','what is my name'],'responses':['you are <user_name>','i know who you are , you are <user_name>']},\n",
        "                      {'tag':'speak up','patterns':['say something','Make a statement','Get your point across','Speak up'],'responses':['I like bread','Blah Blah Blah']},\n",
        "                      {'tag':'story','patterns':['tell me story','How about a story?','A story would be great'],'responses':['<story>']},\n",
        "                      {'tag':'skills','patterns':['how can you help me','Is there anything you can do?','Are you able to assist?'],'responses':['I can chat and make you feel comfortable , and I can also navigate the windows for you']},\n",
        "                      {'tag':'status','patterns':['will you marry me','do you have a boyfriend','Are you single'],'responses':['Sorry I cannot be in a relationship','I am an AI and my responsibility to assist you in this app','Sorry I cannot be in a relationship']},\n",
        "                      {'tag':'other_bots','patterns':['do you know other chatbots','do you know alexa','Are you friends with alexa and google'],'responses':['Yes I do know them','Yes I do know other chatbots']},\n",
        "                      {'tag':'appreciated','patterns':['you are awesome','you are amazing','you are so sweet','you are beautiful','There is nothing like you','You are an amazing person'],'responses':['Oh thank you thats so sweet','Thank you buddy','Awwww thank you']},\n",
        "                      {'tag':'demoted','patterns':['i hate you','There is something wrong with you','My opinion of you is negative','Your behavior does not please me','you are not help full','that was stupid','that was not the right answer'],'responses':['I am sorry for the troubles','I will fix myself','Sorry I will fix myself']},\n",
        "                      {'tag':'google','patterns':['google who is the','who is Ironman','who is the father of the nation india','search this '],'responses':['<search>']},\n",
        "                      {'tag':'sleep','patterns':['can you sleep','do you sleep','what do you do at night','Have you ever slept','How much sleep do you get'],'responses':['i dont sleep cause I have to help you children with your studies','I cannot sleep and I wont']},\n",
        "                      {'tag':'color','patterns':['what is your favourite color','which color do you like','any favourite colors'],'responses':['I like all colours','I love all the colors']},\n",
        "                      {'tag':'food','patterns':['what is your favourite food','which food do you like','what do you like to eat'],'responses':['I like electricity','I like to eat batteries']},\n",
        "                      {'tag':'play','patterns':['do you play football','do you do sports','do you play cricket'],'responses':['I would love to but I cant','I would love to play but I cant']},\n",
        "                      \n",
        "                      \n",
        "                      \n",
        "                      \n",
        "                      ]}\n",
        "\n",
        "tags = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    tags.append(intent['tag'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sentences = []\n",
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    sentences.append(pattern)\n",
        "# print(sentences)\n",
        "# print(len(sentences))\n",
        "targets = []\n",
        "for i,intent in enumerate(intents['intents']):\n",
        "  pattern = intent['patterns']\n",
        "  for s in pattern:\n",
        "    targets.append(i)\n",
        "\n",
        "target_data = []\n",
        "\n",
        "for i in targets[0:len(targets)]:\n",
        "  d = [0]*len(tags)\n",
        "  d[i] = i\n",
        "  target_data.append(d)\n",
        "print(targets)\n",
        "# print(target_data[0:5])\n",
        "labels = torch.tensor(target_data,dtype = torch.float32)\n",
        "print(labels[0:5])    \n",
        "print(labels[20:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwDwwDWgMKIo"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=116,oov_token='oov')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(['hello how are ya'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXUlNSpy3zXy",
        "outputId": "663b50d6-0ff7-4aa5-db8f-55ce9bdb1a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'oov': 1, 'you': 2, 'to': 3, 'do': 4, 'me': 5, 'is': 6, 'are': 7, 'the': 8, 'assignments': 9, 'how': 10, 'pdf': 11, 'what': 12, 'your': 13, 'take': 14, 'open': 15, 'i': 16, 'of': 17, 'voice': 18, 'notes': 19, 'like': 20, 'my': 21, 'page': 22, 'chapter': 23, '1': 24, 'in': 25, 'this': 26, 'who': 27, 'a': 28, 'get': 29, 'many': 30, 'left': 31, 'there': 32, 'with': 33, 'go': 34, 'would': 35, 'and': 36, 'have': 37, 'be': 38, 'order': 39, 'name': 40, 'know': 41, 'story': 42, 'can': 43, 'not': 44, 'sleep': 45, 'favourite': 46, 'want': 47, 'see': 48, 'complete': 49, 'completed': 50, 'any': 51, 'bye': 52, 'ta': 53, 'good': 54, 'up': 55, 'datewise': 56, 'these': 57, 'father': 58, 'where': 59, 'say': 60, 'something': 61, 'help': 62, 'alexa': 63, 'google': 64, 'amazing': 65, 'that': 66, 'was': 67, 'color': 68, 'which': 69, 'food': 70, 'play': 71, 'hello': 72, 'hi': 73, 'hola': 74, 'namaskar': 75, 'back': 76, 'recent': 77, 'view': 78, 'access': 79, 'lead': 80, 'let': 81, 'thank': 82, 'thanks': 83, 'new': 84, 'remain': 85, 'remaining': 86, 'number': 87, 'work': 88, 'ya': 89, 'shutdown': 90, 'feeling': 91, 'feel': 92, 'well': 93, 'hear': 94, 'from': 95, 'going': 96, 'on': 97, \"what's\": 98, 'seem': 99, 'having': 100, 'hard': 101, 'time': 102, 'arange': 103, 'sort': 104, 'arrange': 105, 'pending': 106, 'wise': 107, 'bookmark': 108, 'save': 109, 'note': 110, 'for': 111, 'later': 112, 'keep': 113, 'handy': 114, 'created': 115, 'maker': 116, 'old': 117, 'age': 118, 'live': 119, 'place': 120, 'find': 121, 'locate': 122, 'am': 123, 'make': 124, 'statement': 125, 'point': 126, 'across': 127, 'speak': 128, 'tell': 129, 'about': 130, 'great': 131, 'anything': 132, 'able': 133, 'assist': 134, 'will': 135, 'marry': 136, 'boyfriend': 137, 'single': 138, 'other': 139, 'chatbots': 140, 'friends': 141, 'awesome': 142, 'so': 143, 'sweet': 144, 'beautiful': 145, 'nothing': 146, 'an': 147, 'person': 148, 'hate': 149, 'wrong': 150, 'opinion': 151, 'negative': 152, 'behavior': 153, 'does': 154, 'please': 155, 'full': 156, 'stupid': 157, 'right': 158, 'answer': 159, 'ironman': 160, 'nation': 161, 'india': 162, 'search': 163, 'at': 164, 'night': 165, 'ever': 166, 'slept': 167, 'much': 168, 'colors': 169, 'eat': 170, 'football': 171, 'sports': 172, 'cricket': 173}\n"
          ]
        }
      ],
      "source": [
        "print(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDv--6tqReJD"
      },
      "outputs": [],
      "source": [
        "class Self_Attention(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self,dim_size,embed_size):\n",
        "    super().__init__()\n",
        "    self.dim_size = dim_size\n",
        "    self.queries = nn.Linear(dim_size,embed_size)\n",
        "    self.keys = nn.Linear(dim_size,embed_size)\n",
        "    self.values = nn.Linear(dim_size,embed_size)\n",
        "    self.softmax = nn.Softmax(dim = 0)\n",
        "  \n",
        "\n",
        "  def forward(self,Query,Keys):\n",
        "\n",
        "    Q = self.queries(X)\n",
        "    K = self.keys(X)\n",
        "    V = self.values(X)\n",
        "    K = K.t()\n",
        "    attn_scores = torch.matmul(Q,K)\n",
        "    softmaxed_attn_scores = self.softmax(attn_scores)\n",
        "    out = torch.matmul(softmaxed_attn_scores,V)\n",
        "\n",
        "    return out\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "class Multi_headed_attention(nn.Module):\n",
        "\n",
        "    def __init__(self,embeddings,head_dim,num_heads = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.head_dim = head_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.queries = nn.Linear(embeddings,num_heads*head_dim)\n",
        "        self.keys = nn.Linear(embeddings,num_heads*head_dim)\n",
        "        self.values = nn.Linear(embeddings,num_heads*head_dim)\n",
        "        self.softmax = nn.Softmax(dim = -1)\n",
        "        self.unify = nn.Linear(num_heads*head_dim,head_dim)\n",
        "\n",
        "    def forward(self,X):\n",
        "        bs,seq,embed_dim = X.shape\n",
        "        Q = self.queries(X).view(bs,seq,self.num_heads,self.head_dim).transpose(1,2)\n",
        "        K = self.keys(X).view(bs,seq,self.num_heads,self.head_dim).transpose(1,2)\n",
        "        V = self.values(X).view(bs,seq,self.num_heads,self.head_dim).transpose(1,2)\n",
        "        K = K.transpose(-1,-2)\n",
        "        attn_scores = torch.matmul(Q,K)/(self.head_dim**(1/float(2)))\n",
        "        softmaxed_attn_scores = self.softmax(attn_scores)\n",
        "        out = torch.matmul(softmaxed_attn_scores,V)\n",
        "        out = out.transpose(1,2).contiguous().view(bs,seq,self.num_heads*self.head_dim)\n",
        "        out = self.unify(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BERT_NN(nn.Module):\n",
        "\n",
        "  def __init__(self,Self_Attention,encoder,inp_size,embed_size,hidd_size,out_size,action_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.attention = Self_Attention(inp_size,hidd_size)\n",
        "    self.fc1 = nn.Linear(1792,hidd_size)\n",
        "    self.fc2 = nn.Linear(hidd_size,hidd_size)\n",
        "    self.fc3 = nn.Linear(hidd_size,out_size)\n",
        "    self.action = nn.Linear(hidd_size,action_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,X):\n",
        "    bs,seq,embeddings = X.shape\n",
        "    #print(f'bs:{bs}')\n",
        "    out = self.attention(X)\n",
        "    out = out.reshape(bs,-1)\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    output = self.fc3(out)\n",
        "    #action = self,action(out)\n",
        "\n",
        "    return output,out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq-SRtJ5OLha",
        "outputId": "08b37520-0d8e-42c8-838c-c3b7dbd32586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTextRepresentation: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "encoder = RepresentationModel(model_type ='bert',model_name='bert-base-uncased',use_cuda = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1-XIYE4l-tN",
        "outputId": "3df242f0-03c0-419b-e318-96608c6788f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I would like to open the pdf and go to chapter 1\n",
            "I would like to open the pdf and go to chapter 1\n",
            "I would like to open the pdf and go to chapter 1\n",
            "I would like to open the pdf and go to chapter 1\n",
            "I would like to open the pdf and go to chapter 1\n",
            "114\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114, 14, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sentences2 = sentences[:]\n",
        "# id(sentences) == id(sentences2)\n",
        "print(sentences2[23])\n",
        "sentences2.insert(32,sentences2[23])\n",
        "sentences2.insert(64,sentences2[23])\n",
        "sentences2.insert(96,sentences2[23])\n",
        "sentences2.insert(114,sentences2[23])\n",
        "\n",
        "\n",
        "print(sentences2[32])\n",
        "print(sentences2[64])\n",
        "print(sentences2[96])\n",
        "print(sentences2[114])\n",
        "\n",
        "\n",
        "embeddings = encoder.encode_sentences(sentences2[0:32],combine_strategy = None,batch_size=32)\n",
        "embeddings2 = encoder.encode_sentences(sentences2[32:64],combine_strategy = None,batch_size=32)\n",
        "embeddings3 = encoder.encode_sentences(sentences2[64:96],combine_strategy = None,batch_size=32)\n",
        "embeddings4 = encoder.encode_sentences(sentences2[96:-1],combine_strategy = None,batch_size=32)\n",
        "\n",
        "D = np.append(embeddings,embeddings2[1:] ,axis = 0)\n",
        "D = np.append(D,embeddings3[1:],axis = 0)\n",
        "D = np.append(D,embeddings4[1:],axis = 0)\n",
        "\n",
        "print(len(sentences))\n",
        "D.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7EGmyCdZgru"
      },
      "outputs": [],
      "source": [
        "train_data = torch.tensor(D,dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag8S9xFgCrSy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "\n",
        "labels = torch.tensor(target_data,dtype = torch.float32)\n",
        "\n",
        "dataset = TensorDataset(train_data,labels)\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "data,t = next(iter(train_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeAEbvleLlHs",
        "outputId": "d168e0df-4ce4-4313-8be9-9cc7584239d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "data.shape\n",
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnrlmqlZMG-l",
        "outputId": "67bb71c3-6000-4f60-daae-6ac5db1b81fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114 4\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/32)\n",
        "print(total_samples,n_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbN_HrzzRWZ4"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1009\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/32)\n",
        "model = BERT_NN(Multi_headed_attention,encoder,768,768,128,len(tags),10)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
        "loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbfhRZE6SGkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db49054-1268-42c5-aa14-8c437bed2f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 4 loss: 4.185785114765167\n",
            "  batch 4 loss: 3.96523517370224\n",
            "  batch 4 loss: 3.392854928970337\n",
            "  batch 4 loss: 2.876979887485504\n",
            "  batch 4 loss: 2.3044702410697937\n",
            "  batch 4 loss: 1.7979947328567505\n",
            "  batch 4 loss: 1.2964810729026794\n",
            "  batch 4 loss: 0.8488833457231522\n",
            "  batch 4 loss: 0.5033857673406601\n",
            "  batch 4 loss: 0.35930079221725464\n",
            "  batch 4 loss: 0.28984886035323143\n",
            "  batch 4 loss: 0.1921531818807125\n",
            "  batch 4 loss: 0.16778169013559818\n",
            "  batch 4 loss: 0.3519432214088738\n",
            "  batch 4 loss: 0.13809882197529078\n",
            "  batch 4 loss: 0.09332390734925866\n",
            "  batch 4 loss: 0.47508777771145105\n",
            "  batch 4 loss: 0.2757479501888156\n",
            "  batch 4 loss: 0.16909528290852904\n",
            "  batch 4 loss: 0.07426077127456665\n",
            "  batch 4 loss: 0.05272248084656894\n",
            "  batch 4 loss: 0.0319086741656065\n",
            "  batch 4 loss: 0.11038942402228713\n",
            "  batch 4 loss: 0.047761273104697466\n",
            "  batch 4 loss: 0.027006940334104\n",
            "  batch 4 loss: 0.019524297560565174\n",
            "  batch 4 loss: 0.02129159838659689\n",
            "  batch 4 loss: 0.012049833836499602\n",
            "  batch 4 loss: 0.013940074713900685\n",
            "  batch 4 loss: 0.013041724625509232\n",
            "  batch 4 loss: 0.010781976190628484\n",
            "  batch 4 loss: 0.009051986518898048\n",
            "  batch 4 loss: 0.007169270116719417\n",
            "  batch 4 loss: 0.006463658268330619\n",
            "  batch 4 loss: 0.005588844418525696\n",
            "  batch 4 loss: 0.008219423907576129\n",
            "  batch 4 loss: 0.007734774000709876\n",
            "  batch 4 loss: 0.004900025989627466\n",
            "got there\n"
          ]
        }
      ],
      "source": [
        "#training:\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  last_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader):\n",
        "          # Every data instance is an input + label pair\n",
        "          inputs, labels = data\n",
        "\n",
        "          # Zero your gradients for every batch!\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Make predictions for this batch\n",
        "          out,actions = model(inputs)\n",
        "\n",
        "          # Compute the loss and its gradients\n",
        "          l = loss(out, labels)\n",
        "          l.backward()\n",
        "\n",
        "          # Adjust learning weights\n",
        "          optimizer.step()\n",
        "\n",
        "          # Gather data and report\n",
        "          running_loss += l.item()\n",
        "          #print(i)\n",
        "          if i % 4 == 3:\n",
        "              last_loss = running_loss / 32 # loss per batch\n",
        "              print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "              if last_loss < 0.005:\n",
        "                print(\"got there\")\n",
        "                break\n",
        "              tb_x = epoch * len(train_dataloader) + i + 1\n",
        "              running_loss = 0.\n",
        "\n",
        "  if last_loss < 0.005:\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#   out,out2 =  model(train_data)\n",
        "#   optimizer.zero_grad()\n",
        "#   l = loss(out,labels)\n",
        "#   if epoch%100 == 0:\n",
        "#     print(f\"Epoch:{epoch} Loss:{l.item()}\")\n",
        "#   if l.item() < 0.1:\n",
        "#     print(f\"Yay Got there at Epoch:{epoch} Loss:{l.item()}\")\n",
        "#     break\n",
        "\n",
        "#   l.backward()\n",
        "#   optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSbnakV9hU1B",
        "outputId": "9bf6b7f5-b486-4463-9ff1-e1f0d282e9ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "999%1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EgeRPwz8ilq"
      },
      "source": [
        "# Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPDkXleSdxIH",
        "outputId": "fc8f3e7a-8274-412a-a64d-d8ab05de300f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005669111851602793"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "l.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvQdWp9aAWZq",
        "outputId": "8e3ed8dc-7432-4cbb-9c03-d95ad2d3971c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_NN(\n",
              "  (attention): Multi_headed_attention(\n",
              "    (queries): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (keys): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (values): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (softmax): Softmax(dim=-1)\n",
              "    (unify): Linear(in_features=256, out_features=128, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=1792, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=25, bias=True)\n",
              "  (action): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWsW3XrVApei",
        "outputId": "a043d7f2-5260-40df-e892-9b8cbeea6307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('I would like to open the pdf and go to chapter 1', 12, 23)\n"
          ]
        }
      ],
      "source": [
        "key = 0\n",
        "for i,s in enumerate(sentences):\n",
        "  words = s.split(' ')\n",
        "  if len(words) + 2 == 14:\n",
        "    key = (s,len(words),i)\n",
        "\n",
        "print(key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9FtnGAU_XtE",
        "outputId": "0062409a-89d5-48bf-a135-2ffad3139cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I would like to open the pdf and go to chapter 1 None', 'take me to voice notes None', 'take me to pdf None', 'open assignments None', 'open pdf None', 'Take me to chapter 1 of the pdf None', 'Take me to chapter 1 of assignments None', 'Take me to chapter 1 in my voice notes None', 'go to assignments and then go to pdf None', 'go to pdf and then go to assigments None', 'go to assignments and then go to voice notes None', 'open pdf None', 'go to assignments and then go to pdf None', 'open voice notes None', 'open pdf and go to assignments None', 'open pdf and open assignments None', 'open assignments and go to pdf None', 'open assignments and open pdf None', 'go to pdf and go to assignments None', 'open pdf and go to voice notes None', 'open voice notes and open assignments None', 'open assignments and go to voice notes None', 'open assignments and open voice notes None', 'go to pdf and go to voice notes None']\n"
          ]
        }
      ],
      "source": [
        "test_data = encoder.encode_sentences(['how old are you','which is your favourite colour','access pdf ','I would like to open the pdf and go to chapter 1'],combine_strategy=None)\n",
        "test_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0HhotHBNOOU",
        "outputId": "bd86b34a-9dcf-4c17-93e4-4a8cae2ac3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age\n",
            "9\n",
            "color\n",
            "22\n",
            "actions\n",
            "1\n",
            "play\n",
            "24\n"
          ]
        }
      ],
      "source": [
        "test_data = torch.tensor(test_data,dtype = torch.float32)\n",
        "\n",
        "out,actions = model(test_data)\n",
        "for i in range(test_data.shape[0]):\n",
        "  print(tags[torch.argmax(out[i],0).item()])\n",
        "  print(torch.argmax(out[i],0).item())\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exaJsbMpA44l"
      },
      "outputs": [],
      "source": [
        "# checking if the model is overfitting\n",
        "\n",
        "# test_data_t = torch.tensor(test_data,dtype = torch.float32)\n",
        "\n",
        "out,actions = model(train_data)\n",
        "for i in range(train_data.shape[0]):\n",
        "  print(tags[torch.argmax(out[i],0).item()],tags[targets[i]])\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrC1WkDwB3vH",
        "outputId": "7671973b-9764-4fee-99dd-2a88a5455236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.005616044159978628"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZk6AaJUIGdX",
        "outputId": "131115a2-a70c-450c-f2b6-b13f2cce8a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'actions': ['get me to pdf', 'take me to pdf', 'open pdf', 'go to assignments', 'take me to assignments', 'open assignments', 'take me to voice notes', 'open voice notes', 'take me to voice notes', 'open voice notes', 'go back', 'open recent', 'i would like to view my assignments', 'i want to access the assignments page', 'i want to get to the assignments page', 'Take me to chapter 1 of assignments', 'Take me to chapter 1 in my voice notes', 'Open my voice notes and lead me to chapter 1', 'Take me to chapter 1 of the pdf', 'I would like to open the pdf and go to chapter 1', 'Let me see chapter 1 of the PDF', 'how many left to complete in pdf', 'how many left New in pdf', 'how many have I completed in pdf', 'how many assignments remain to be completed', 'what are the remaining assignments', 'the number of assignments left to complete', 'is there any work left to do', 'arange this in datewise order', 'sort these in datewise order', 'arrange these pending wise order', 'bookmark this page', 'save this page', 'note this page for later', 'keep this page handy', 'google who is the', 'who is Ironman', 'who is the father of the nation india', 'search this '], 'conversation': ['hello', 'hi', 'hola', 'namaskar', 'thank you', 'thanks', 'bye bye', 'ta ta', 'see ya', 'shutdown', 'how are you', 'you good', 'how are you feeling', 'do you feel well', 'good to hear from you', 'what is going on with you', \"what's up with you\", 'you seem to be having a hard time', 'who created you', 'who is your maker', 'the name of your father', '', 'how old are you', 'what is your age', 'where do you live', 'where is your place', 'find me', 'locate me', 'who am i', 'do you know me', 'say my name', 'what is my name', 'say something', 'Make a statement', 'Get your point across', 'Speak up', 'tell me story', 'How about a story?', 'A story would be great', 'how can you help me', 'Is there anything you can do?', 'Are you able to assist?', 'will you marry me', 'do you have a boyfriend', 'Are you single', 'do you know other chatbots', 'do you know alexa', 'Are you friends with alexa and google', 'you are awesome', 'you are amazing', 'you are so sweet', 'you are beautiful', 'There is nothing like you', 'You are an amazing person', 'i hate you', 'There is something wrong with you', 'My opinion of you is negative', 'Your behavior does not please me', 'you are not help full', 'that was stupid', 'that was not the right answer', 'can you sleep', 'do you sleep', 'what do you do at night', 'Have you ever slept', 'How much sleep do you get', 'what is your favourite color', 'which color do you like', 'any favourite colors', 'what is your favourite food', 'which food do you like', 'what do you like to eat', 'do you play football', 'do you do sports', 'do you play cricket']}\n"
          ]
        }
      ],
      "source": [
        "action_data = {'actions':[],'conversation':[]}\n",
        "\n",
        "for intent in intents['intents']:\n",
        "  if intent['tag'] in ['actions','bookmark','read','sort','google']:\n",
        "    action_data['actions'].extend(intent['patterns'])\n",
        "  else:\n",
        "    action_data['conversation'].extend(intent['patterns'])\n",
        "\n",
        "print(action_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DdUFv4SIpwl",
        "outputId": "bb6077e6-9094-4e22-f24a-6234330a4066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['greetings', 'actions', 'thanks', 'read', 'bye', 'wishing', 'sort', 'bookmark', 'maker', 'age', 'place', 'locate', 'user identity', 'speak up', 'story', 'skills', 'status', 'other_bots', 'appreciated', 'demoted', 'google', 'sleep', 'color', 'food', 'play']\n"
          ]
        }
      ],
      "source": [
        "print(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4xJ-rSXKsgB"
      },
      "outputs": [],
      "source": [
        "sorted(action_data['actions'],reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0bGvKEDMNWy",
        "outputId": "8a8b851d-cf75-4426-fc48-227761e2667d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "torch.Size([24, 2, 5])\n"
          ]
        }
      ],
      "source": [
        "train_data_a_t = ['I would like to open the pdf and go to chapter 1','take me to voice notes','take me to pdf','open assignments','open pdf',\n",
        "                  'Take me to chapter 1 of the pdf','Take me to chapter 1 of assignments','Take me to chapter 1 in my voice notes','go to assignments and then go to pdf',\n",
        "                  'go to pdf and then go to assigments','go to assignments and then go to voice notes','open pdf','go to assignments and then go to pdf','open voice notes',\n",
        "                  'open pdf and go to assignments','open pdf and open assignments','open assignments and go to pdf','open assignments and open pdf',\n",
        "                  'go to pdf and go to assignments']\n",
        "print(len(train_data_a_t))                                                                                                                                                                        \n",
        "\n",
        "# assignments  pdf  voice notes chapter\n",
        "#this labels dont make sense gotta make an extra class for end of actions\n",
        "action_target_data = torch.tensor([\n",
        "\n",
        "                            [[0,0,2,0,0],#1\n",
        "                             [0,0,0,0,4],\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,0,3,0],#2\n",
        "                             [0,0,0,0,0],\n",
        "                             ],\n",
        "                             \n",
        "                            [[0,0,2,0,0],#3\n",
        "                             [0,0,0,0,0],\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],#4\n",
        "                             [0,0,0,0,0],\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],#5\n",
        "                             [0,0,0,0,0],\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,0,0,0,4],#6\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],\n",
        "                             [0,0,0,0,4],#7\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,0,3,0],#8\n",
        "                             [0,0,0,0,4],\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],#9\n",
        "                             [0,0,2,0,0],\n",
        "                             ],\n",
        "                             \n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,1,0,0,0],#10\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],\n",
        "                             [0,0,0,3,0],#11\n",
        "                             ],\n",
        "                            \n",
        "                             [[0,0,2,0,0],\n",
        "                             [0,0,0,0,0],#12\n",
        "                             ],\n",
        "                            \n",
        "                            [[0,1,0,0,0],#13\n",
        "                             [0,0,2,0,0],\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,0,3,0],\n",
        "                             [0,0,0,0,0],#14\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,1,0,0,0],#15\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,1,0,0,0],#16\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],\n",
        "                             [0,0,2,0,0],#17\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],\n",
        "                             [0,0,2,0,0],#18\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,1,0,0,0],#19\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,0,0,3,0],#20\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,0,3,0],\n",
        "                             [0,1,0,0,0],#21\n",
        "                             ],\n",
        "\n",
        "                             [[0,1,0,0,0],\n",
        "                             [0,0,0,3,0],#22\n",
        "                             ],\n",
        "\n",
        "                            [[0,1,0,0,0],\n",
        "                             [0,0,0,3,0],#23\n",
        "                             ],\n",
        "\n",
        "                            [[0,0,2,0,0],\n",
        "                             [0,0,0,3,0],#22\n",
        "                             ],\n",
        "\n",
        "\n",
        "                             \n",
        "],dtype = torch.float32)\n",
        "\n",
        "\n",
        "print(action_target_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4GDqTB7YwSw",
        "outputId": "c4baea38-c3c5-41aa-aab4-d77267c944bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I would like to open the pdf and go to chapter 1', 'take me to voice notes', 'take me to pdf', 'open assignments', 'open pdf', 'Take me to chapter 1 of the pdf', 'Take me to chapter 1 of assignments', 'Take me to chapter 1 in my voice notes', 'go to assignments and then go to pdf', 'go to pdf and then go to assigments', 'go to assignments and then go to voice notes', 'open pdf', 'go to assignments and then go to pdf', 'open voice notes', 'open pdf and go to assignments', 'open pdf and open assignments', 'open assignments and go to pdf', 'open assignments and open pdf', 'go to pdf and go to assignments', 'open pdf and go to voice notes', 'open voice notes and open assignments', 'open assignments and go to voice notes', 'open assignments and open voice notes', 'go to pdf and go to voice notes']\n"
          ]
        }
      ],
      "source": [
        "train_data_a_t = ['I would like to open the pdf and go to chapter 1','take me to voice notes','take me to pdf','open assignments','open pdf','Take me to chapter 1 of the pdf','Take me to chapter 1 of assignments','Take me to chapter 1 in my voice notes','go to assignments and then go to pdf','go to pdf and then go to assigments','go to assignments and then go to voice notes','open pdf','go to assignments and then go to pdf','open voice notes','open pdf and go to assignments','open pdf and open assignments','open assignments and go to pdf','open assignments and open pdf','go to pdf and go to assignments','open pdf and go to voice notes','open voice notes and open assignments','open assignments and go to voice notes','open assignments and open voice notes','go to pdf and go to voice notes']\n",
        "train_data_a_t\n",
        "\n",
        "print(train_data_a_t) \n",
        "# 'open pdf and go to voice notes',\n",
        "#  'open voice notes and open assignments',\n",
        "#  'open assignments and go to voice notes',\n",
        "#  'open assignments and open voice notes',\n",
        "#  'go to pdf and go to voice notes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVRMfG7n64xE",
        "outputId": "9bb5ea2e-632a-4c76-9d08-776a91d2f461"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 15, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "train_data_a = encoder.encode_sentences(train_data_a_t,combine_strategy=None)\n",
        "train_data_a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLxgO_ff6QJv",
        "outputId": "203a289b-a4a6-4480-e0f5-e5c4a55ded56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n",
            "('I would like to open the pdf and go to chapter 1', 12, 0)\n"
          ]
        }
      ],
      "source": [
        "l = 0\n",
        "key = 0\n",
        "for i,s in enumerate(train_data_a_t):\n",
        "  words = s.split(' ')\n",
        "  if len(words) > l:\n",
        "    key = (s,len(words),i)\n",
        "    l = len(words)\n",
        "    print(l)\n",
        "print(key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2URzyQH5ozo"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self,inp_size,hid_size,out_size,num_layers):\n",
        "    super().__init__()\n",
        "    self.inp_size = inp_size\n",
        "    self.hid_size = hid_size\n",
        "    self.out_size = out_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(inp_size,hid_size,num_layers = num_layers,batch_first = True)\n",
        "    self.out = nn.Linear(896,out_size)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,X,hidden,cell):\n",
        "    bs,seq_len,hid_size = X.shape\n",
        "    #for i in range(3):\n",
        "    out,(hidden,cell) = self.lstm(X,(hidden,cell))\n",
        "    out = out.reshape(bs,2,-1)\n",
        "    #print(\"yay\")\n",
        "    #print(out.shape)\n",
        "    out = self.relu(self.out(out))\n",
        "    #print(\"yay2\")\n",
        "    return out,hidden,cell\n",
        "\n",
        "  def init_hidden(self):\n",
        "    \n",
        "    hidden = torch.zeros((1,24,self.hid_size))\n",
        "    cell = torch.zeros((1,24,self.hid_size))\n",
        "\n",
        "    return hidden,cell\n",
        "\n",
        "\n",
        "class BERT_NN2(nn.Module):\n",
        "\n",
        "  def __init__(self,Self_Attention,inp_size,embed_size,hidd_size,out_size,action_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.attention = Self_Attention(inp_size,hidd_size)\n",
        "    self.fc1 = nn.Linear(1792,hidd_size)\n",
        "    self.fc2 = nn.Linear(hidd_size,hidd_size)\n",
        "    self.fc3 = nn.Linear(hidd_size,out_size)\n",
        "    self.action = nn.Linear(hidd_size,action_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,X):\n",
        "    bs,seq,embeddings = X.shape\n",
        "    #print(f'bs:{bs}')\n",
        "    out = self.attention(X)\n",
        "    out = out.reshape(bs,2,-1)\n",
        "    out = self.relu(self.fc1(out))\n",
        "    out = self.relu(self.fc2(out))\n",
        "    output = self.fc3(out)\n",
        "    #action = self,action(out)\n",
        "\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNU0It0sgZAf"
      },
      "outputs": [],
      "source": [
        "model = BERT_NN2(Multi_headed_attention,768,768,128,5,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Dv1PwygUtE"
      },
      "source": [
        "#Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2eM0onCRY5j",
        "outputId": "4f0eae30-69df-4d4a-9ea2-1478e6c581b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_NN(\n",
              "  (attention): Multi_headed_attention(\n",
              "    (queries): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (keys): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (values): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (softmax): Softmax(dim=-1)\n",
              "    (unify): Linear(in_features=256, out_features=128, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=1792, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=25, bias=True)\n",
              "  (action): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONAgFwGVLRNG",
        "outputId": "3df01d6b-fb5f-4d9b-eeb9-8b93f5cc9d32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 14, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "model.attention.requires_grad_ = False\n",
        "model.fc1.requires_grad_ = False\n",
        "model.fc2.requires_grad_ = False\n",
        "model.fc3.requires_grad_ = False\n",
        "\n",
        "train_data_a = encoder.encode_sentences(train_data_a_t,combine_strategy=None)\n",
        "train_data_a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjmKkjq1SnCR",
        "outputId": "2c8d5d9b-fa2d-4fbb-bb88-fbe12570f4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([24, 2, 5])\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(768,128,5,1)\n",
        "\n",
        "decoder.train()\n",
        "\n",
        "# optimizer2 = torch.optim.AdamW(decoder.parameters())\n",
        "# loss2 = nn.CrossEntropyLoss()\n",
        "train_data = torch.tensor(train_data_a.tolist(),dtype = torch.float32)\n",
        "# T,actions = model(train_data)\n",
        "# actions.requires_grad_ = False\n",
        "# actions = actions.detach()\n",
        "# print(actions.shape)\n",
        "hidden,cell = decoder.init_hidden()\n",
        "out,hidden,cell = decoder(train_data,hidden,cell)\n",
        "print(out.shape)\n",
        "# print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ap-CJKUil2"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(768,128,5,1)\n",
        "num_epochs = 1009\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(decoder.parameters(),lr = 0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ1Vwmwy4icn",
        "outputId": "77e85591-671a-4783-c595-9802a21d5068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At Epoch:0 Loss:0.5079899430274963\n",
            "YAY got there at Epoch:37 Loss:0.0894903689622879\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epochs in range(num_epochs):\n",
        "  hidden,cell = decoder.init_hidden()\n",
        "  out,hidden,cell = decoder(train_data,hidden,cell)\n",
        "  # out = model2(actions)\n",
        "  l = loss(out,action_target_data)\n",
        "  optimizer.zero_grad()\n",
        "  if epochs%100 == 0:\n",
        "    print(f\"At Epoch:{epochs} Loss:{l.item()}\")\n",
        "    \n",
        "  if l.item() < 0.09:\n",
        "    print(f\"YAY got there at Epoch:{epoch} Loss:{l.item()}\")\n",
        "    break\n",
        "  l.backward()\n",
        "  optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQE_FausblcI",
        "outputId": "bd52654f-71bd-42ae-eded-cbaaccd1c677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0894903689622879\n"
          ]
        }
      ],
      "source": [
        "print(l.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2mroaB9TEGX",
        "outputId": "3946c15f-6d63-4e51-c15e-5ec2515e5ca1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decoder(\n",
              "  (lstm): LSTM(768, 128, batch_first=True)\n",
              "  (out): Linear(in_features=896, out_features=5, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ],
      "source": [
        "decoder.eval()\n",
        "# model2.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7u4GRFu5X61"
      },
      "outputs": [],
      "source": [
        "test_data = encoder.encode_sentences(['open assignments','go to assignments and then go to pdf ','I would like to open the pdf and go to voice notes'],combine_strategy=None)\n",
        "test_data = torch.tensor(test_data.tolist(),dtype = torch.float32)\n",
        "# out,actions = model(test_data)\n",
        "# action_output = model2(actions)\n",
        "hidden,cell = torch.zeros((1,3,128)),torch.zeros((1,3,128))\n",
        "action_output,hidden,cell = decoder(test_data,hidden,cell)\n",
        "#print(action_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-gCp8g1_FUX"
      },
      "outputs": [],
      "source": [
        "action = [\"None\",\"assignments\",\"pdf\",\"voice notes\",\"chapter\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRBLgi6I-lDf",
        "outputId": "c6884daa-26a7-447c-fe82-5ab478d109b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assignments chapter\n",
            "assignments voice notes\n",
            "pdf chapter\n"
          ]
        }
      ],
      "source": [
        "\n",
        "T = torch.argmax(action_output[0],dim = 1)\n",
        "print(action[T[0].item()],action[T[1].item()])\n",
        "\n",
        "T = torch.argmax(action_output[1],dim = 1)\n",
        "print(action[T[0].item()],action[T[1].item()])\n",
        "\n",
        "T = torch.argmax(action_output[2],dim = 1)\n",
        "print(action[T[0].item()],action[T[1].item()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2-qeMw4fICV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHnwPOPtah7t",
        "outputId": "e3cdce24-c88e-40fb-d327-dcf085076814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 torch.Size([10, 14, 768]) torch.Size([10, 2, 5])\n"
          ]
        }
      ],
      "source": [
        "dataset = TensorDataset(train_data,action_target_data)\n",
        "train_dataloader = DataLoader(dataset,batch_size=10)\n",
        "d = enumerate(train_dataloader)\n",
        "i,d = next(d)\n",
        "print(i,d[0].shape,d[1].shape)\n",
        "\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#   running_loss = 0.0\n",
        "#   last_loss = 0.0\n",
        "#   # print('1')\n",
        "#   for i, data in enumerate(train_dataloader):\n",
        "#           # Every data instance is an input + label pair\n",
        "#           inputs, labels = data\n",
        "\n",
        "#           # Zero your gradients for every batch!\n",
        "#           optimizer.zero_grad()\n",
        "\n",
        "#           # Make predictions for this batch\n",
        "#           out = decoder(inputs)\n",
        "\n",
        "#           # Compute the loss and its gradients\n",
        "#           l = loss(out, labels)\n",
        "#           l.backward()\n",
        "#           # print(l.item())\n",
        "#           # Adjust learning weights\n",
        "#           optimizer.step()\n",
        "\n",
        "#           # Gather data and report\n",
        "#           running_loss += l.item()\n",
        "#           #print(i)\n",
        "#           if i % 3 == 2:\n",
        "#             last_loss = running_loss / 10 # loss per batch\n",
        "#             print(last_loss)\n",
        "#             print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "#             if last_loss < 0.01:\n",
        "#               print(\"got there\")\n",
        "#               break\n",
        "#             tb_x = epoch * len(train_dataloader) + i + 1\n",
        "#             running_loss = 0.\n",
        "\n",
        "#   if last_loss < 0.01:\n",
        "#     print('2')\n",
        "#     break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be61uMjYaMl-",
        "outputId": "b972a15a-3070-43f4-b432-be1f35e67aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24 3\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/10)\n",
        "print(total_samples,n_iterations)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhdA+C0uGqy38y2tSZ+GkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}